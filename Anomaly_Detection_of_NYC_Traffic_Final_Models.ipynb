{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting NYC Traffic Anomalies Final Models Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will walkthrough code to automate fitting the final model I created in the last notebook to all of the senors. If you are wondering how I got to the model we will be using, I recommend looking at the <b>Modeling Notebook</b> before continuing on with this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import folium\n",
    "from keras.losses import mean_squared_error\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Connection to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to connect to a database because there is important informationt that we will generate that we want to be able to keep track of. For example, we want to be able to store the metrics for the final model of each sensor so we can do further analysis on the overall state of our system. I'm using sqlite3 for my database, but you can use any one you want. However, the code will probably be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the database you want to use. If you are creating a new database\n",
    "# the code is the same. Just name the database in a way that makes sense to you and it will\n",
    "# be created in the same folder as this notebook.\n",
    "conn = sqlite3.connect('traffic_flow.db')\n",
    "\n",
    "# Instantiate a cursor instance to interact with your database\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f9b12b94500>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table - MODEL_METRICS\n",
    "c.execute('''CREATE TABLE MODEL_METRICS\n",
    "             ([sensor_id] INTEGER,\n",
    "             [date] DATETIME,\n",
    "             [data_from] DATETIME,\n",
    "             [data_to] DATETIME,\n",
    "             [training_mean] FLOAT,\n",
    "             [training_std] FLOAT,\n",
    "             [baseline_loss] FLOAT,\n",
    "             [model_train_loss] FLOAT,\n",
    "             [model_test_loss] FLOAT,\n",
    "             PRIMARY KEY (sensor_id, date))''')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f9b12b94500>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute('''DROP TABLE MODEL_METRICS''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commit the changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sensor_dfs.pickle', 'rb') as handle:\n",
    "    sensor_dfs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the steps we will use for each sensor (explained in Modeling Notebook)\n",
    "X_steps = 18\n",
    "y_steps = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model for Each Sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensor_etl(df, ID, filename, X_steps, y_steps):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #file suffix\n",
    "    if start_year == end_year:\n",
    "        suffix = str(start_year)\n",
    "    else:\n",
    "        suffix = str(start_year) + '_' + str(end_year)\n",
    "        \n",
    "    #import libraries\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    # Group the time series into weekly buckets\n",
    "    sens_weekly = sens_clean['SPEED'].resample('7D')\n",
    "\n",
    "    # Take the mean of each group \n",
    "    sens_weekly_mean = sens_weekly.mean()\n",
    "    \n",
    "    #plot the generic trend and save the figure\n",
    "    fig1, ax1 = plt.subplots(figsize=(16,8))\n",
    "    sens_weekly_mean.plot(color='blue', ax=ax1);\n",
    "    fig1.set_facecolor('white')\n",
    "    fig1.suptitle('Weekly Traffic Speeds (' + filename + ')')\n",
    "    ax1.grid(axis='y')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Average Traffic Speed (MPH)')\n",
    "    ax1.set_facecolor('white')\n",
    "    for x in ['bottom', 'top', 'right', 'left']:\n",
    "        ax1.spines[x].set_color('black')\n",
    "    \n",
    "    plt.savefig(filename + '_weekly_trend_' + suffix, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "    #aggregate all of the data to each weekday and plot that data\n",
    "    weekly_agg = day_of_week_agg(sens_clean)\n",
    "\n",
    "    fig2, ax2 = plt.subplots(figsize=(16,8));\n",
    "    for i in range(7):\n",
    "        colors= ['blue', 'red', 'orange', 'green', 'gray', 'purple', 'darkblue']\n",
    "        weekly_agg[i]['SPEED'].plot(ax=ax2, color=colors[i], alpha=0.75);\n",
    "    color='black'   \n",
    "    fig2.legend(labels=['Monday', 'Tuesday', 'Wednesday', 'Thurday', 'Friday', 'Saturday', 'Sunday']\n",
    "               , edgecolor='black', framealpha=1, loc=(.85,.101), facecolor='white')\n",
    "    fig2.set_facecolor('white')\n",
    "    fig2.suptitle('Average Traffic Speeds Per Day (' + filename + ')', color=color)\n",
    "    ax2.grid(axis='y')\n",
    "    ax2.set_xticks([287, 251, 215, 179, 143, 107, 71, 35, 0])\n",
    "    ax2.set_xticklabels(['12am', '9pm', '6pm', '3pm', '12pm', '9am', '6am', '3am', '12am'], color=color)\n",
    "    ax2.set_xlabel('Time', color=color)\n",
    "    ax2.set_ylabel('Average Traffic Speed (MPH)', color=color)\n",
    "    ax2.set_facecolor('white')\n",
    "    ax2.tick_params(axis='y', colors=color)\n",
    "    for x in ['bottom', 'top', 'right', 'left']:\n",
    "        ax2.spines[x].set_color('black')\n",
    "    plt.savefig(filename + '_weekdays_' + suffix, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    #standardize data and split into train, val and test sets\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_dfs(dataframe = sens_clean, column = 'SPEED', X_steps = X_steps, y_steps = y_steps, standardize=True)\n",
    "\n",
    "    \n",
    "    #------MODELING------\n",
    "    #Baseline\n",
    "    y_pred = X_val[:, -y_steps:]\n",
    "\n",
    "    baseline_loss = np.mean(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "    #Final Model\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[X_steps, 1]),\n",
    "        keras.layers.Dense(40),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(40),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(20),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(y_steps)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='Adam', loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs = 5, verbose=0)\n",
    "    train_loss = history.history['loss'][-1]\n",
    "    val_loss = model.evaluate(X_val, y_val, verbose=0)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    \n",
    "    c.execute(f'''\n",
    "                    INSERT INTO MODEL_PERFORMANCE_2015_2020 (sensor_id,\n",
    "                                                   model4_train_loss,\n",
    "                                                   model4_test_loss,\n",
    "                                                   model5_train_loss,\n",
    "                                                   model5_test_loss,\n",
    "                                                   final_model)\n",
    "                                VALUES (\n",
    "                                        {ID},\n",
    "                                        {date},\n",
    "                                        {data_from},\n",
    "                                        {data_to},\n",
    "                                        {training_mean},\n",
    "                                        {training_std},\n",
    "                                        {baseline_loss}\n",
    "                                        {train_loss},\n",
    "                                        {val_loss})\n",
    "\n",
    "             ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    \n",
    "    model.save(filename + '_model_' + suffix)\n",
    "      \n",
    "    clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
